{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us begin by pre-training a model using a head with 1000 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train for 4 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using synthetic train and test datasets for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.dataset import SyntheticImageClassificationDataset\n",
    "\n",
    "train_dataset = SyntheticImageClassificationDataset.from_config({\n",
    "    \"batchsize_per_replica\": 32,\n",
    "    \"num_samples\": 2000,\n",
    "    \"crop_size\": 224,\n",
    "    \"class_ratio\": 0.5,\n",
    "    \"seed\": 0,\n",
    "    \"use_shuffle\": True,\n",
    "    \"split\": \"train\",\n",
    "})\n",
    "test_dataset = SyntheticImageClassificationDataset.from_config({\n",
    "    \"batchsize_per_replica\": 32,\n",
    "    \"num_samples\": 200,\n",
    "    \"crop_size\": 224,\n",
    "    \"class_ratio\": 0.5,\n",
    "    \"seed\": 0,\n",
    "    \"use_shuffle\": False,\n",
    "    \"split\": \"test\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a ResNet 50 model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.models import ResNet\n",
    "\n",
    "model = ResNet.from_config({\n",
    "    \"num_blocks\": [3, 4, 6, 3],\n",
    "    \"small_input\": False,\n",
    "    \"zero_init_bn_residuals\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a head with 1000 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.heads import FullyConnectedHead\n",
    "\n",
    "head = FullyConnectedHead(unique_id=\"default_head\", num_classes=1000, in_plane=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us attach the head to the final block of the model.\n",
    "\n",
    "For ResNet 50, we want to attach to the `3`<sup>rd</sup> block in the `4`<sup>th</sup> layer (based on `[3, 4, 6, 3]`). The blocks use 0 indexing, so this maps to `\"block3-2\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_heads({\"block3-2\": {head.unique_id: head}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a cross entropy loss from Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "loss = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the optimizer, we will be using SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.optim import build_optimizer\n",
    "\n",
    "\n",
    "optimizer = build_optimizer({\n",
    "    \"name\": \"sgd\",\n",
    "    \"lr\": {\"name\": \"step\", \"values\": [0.1, 0.01]},\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"momentum\": 0.9,\n",
    "    \"num_epochs\": num_epochs\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to track the top-1 and top-5 accuracies of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.meters import AccuracyMeter\n",
    "\n",
    "meters = [AccuracyMeter(topk=[1, 5])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a directory to save the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "pretrain_checkpoint_dir = f\"/tmp/checkpoint_{time.time()}\"\n",
    "os.mkdir(pretrain_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `ProgressBarHook` to monitor the progress, `LossLrMeterLoggingHook` to monitor the loss and `CheckpointHook` to save the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.hooks import CheckpointHook, LossLrMeterLoggingHook, ProgressBarHook\n",
    "\n",
    "hooks = [\n",
    "    ProgressBarHook(),\n",
    "    LossLrMeterLoggingHook(),\n",
    "    CheckpointHook(pretrain_checkpoint_dir, input_args={})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the components ready to setup our pre-training task which trains for 4 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.tasks import ClassificationTask\n",
    "\n",
    "pretrain_task = (\n",
    "    ClassificationTask()\n",
    "    .set_num_epochs(num_epochs)\n",
    "    .set_loss(loss)\n",
    "    .set_model(model)\n",
    "    .set_optimizer(optimizer)\n",
    "    .set_meters(meters)\n",
    "    .set_hooks(hooks)\n",
    "    .set_dataset(train_dataset, \"train\")\n",
    "    .set_dataset(test_dataset, \"test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train using a local trainer instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1031 123603.710 local_trainer.py:18] Using GPU, CUDA device index: 0\n"
     ]
    }
   ],
   "source": [
    "from classy_vision.trainer import LocalTrainer\n",
    "\n",
    "trainer = LocalTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1031 123606.480 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 123738.429 classy_trainer.py:53] Syncing meters on phase end...#########|\n",
      "I1031 123738.430 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 123738.431 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 123738.432 loss_lr_meter_logging_hook.py:88] Rank: 0, train phase: 0, processed batches: 63\n",
      "train loss: 0.14879648647611105, LR rate: 0.1\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 0.968999981880188, 'top_5': 0.984000027179718}}\n",
      "I1031 123738.433 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n",
      "I1031 123739.342 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 123747.718 classy_trainer.py:53] Syncing meters on phase end...         |\n",
      "I1031 123747.719 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 123747.720 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 123747.721 loss_lr_meter_logging_hook.py:88] Rank: 0, test phase: 0, processed batches: 7\n",
      "test loss: 0.0, LR rate: 0.1\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0, 'top_5': 1.0}}\n",
      "I1031 123747.722 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n",
      "I1031 123748.721 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 123911.751 classy_trainer.py:53] Syncing meters on phase end...#########|\n",
      "I1031 123911.752 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 123911.754 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 123911.755 loss_lr_meter_logging_hook.py:88] Rank: 0, train phase: 1, processed batches: 63\n",
      "train loss: 0.0, LR rate: 0.1\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0, 'top_5': 1.0}}\n",
      "I1031 123911.755 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n",
      "I1031 123912.665 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 123920.143 classy_trainer.py:53] Syncing meters on phase end...         |\n",
      "I1031 123920.144 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 123920.145 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 123920.147 loss_lr_meter_logging_hook.py:88] Rank: 0, test phase: 1, processed batches: 7\n",
      "test loss: 0.0, LR rate: 0.1\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0, 'top_5': 1.0}}\n",
      "I1031 123920.147 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n",
      "I1031 123921.002 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 124042.216 classy_trainer.py:53] Syncing meters on phase end...#########|\n",
      "I1031 124042.216 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 124042.217 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 124042.218 loss_lr_meter_logging_hook.py:88] Rank: 0, train phase: 2, processed batches: 63\n",
      "train loss: 0.0, LR rate: 0.01\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0, 'top_5': 1.0}}\n",
      "I1031 124042.219 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n",
      "I1031 124043.124 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 124050.833 classy_trainer.py:53] Syncing meters on phase end...         |\n",
      "I1031 124050.834 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 124050.835 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 124050.836 loss_lr_meter_logging_hook.py:88] Rank: 0, test phase: 2, processed batches: 7\n",
      "test loss: 0.0, LR rate: 0.01\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0, 'top_5': 1.0}}\n",
      "I1031 124050.837 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n",
      "I1031 124051.733 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 124211.692 classy_trainer.py:53] Syncing meters on phase end...#########|\n",
      "I1031 124211.692 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 124211.694 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 124211.695 loss_lr_meter_logging_hook.py:88] Rank: 0, train phase: 3, processed batches: 63\n",
      "train loss: 0.0, LR rate: 0.01\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0, 'top_5': 1.0}}\n",
      "I1031 124211.695 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n",
      "I1031 124212.599 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 124219.856 classy_trainer.py:53] Syncing meters on phase end...         |\n",
      "I1031 124219.857 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 124219.858 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 124219.859 loss_lr_meter_logging_hook.py:88] Rank: 0, test phase: 3, processed batches: 7\n",
      "test loss: 0.0, LR rate: 0.01\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0, 'top_5': 1.0}}\n",
      "I1031 124219.860 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550558.022384'...\n"
     ]
    }
   ],
   "source": [
    "trainer.train(pretrain_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is done! Let us now load the saved checkpoint, we will use this later for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1031 124220.689 util.py:453] Attempting to load checkpoint from '/tmp/checkpoint_1572550558.022384'\n",
      "I1031 124220.872 util.py:471] Loaded checkpoint from /tmp/checkpoint_1572550558.022384/checkpoint.torch\n"
     ]
    }
   ],
   "source": [
    "from classy_vision.generic.util import load_checkpoint\n",
    "\n",
    "pretrained_checkpoint = load_checkpoint(pretrain_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will fine tune a model using a head with 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want to train our fine tuning task for 1 just epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-use the same synthetic datasets as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us again create a ResNet 50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.models import ResNet\n",
    "\n",
    "model = ResNet.from_config({\n",
    "    \"num_blocks\": [3, 4, 6, 3],\n",
    "    \"small_input\": False,\n",
    "    \"zero_init_bn_residuals\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine tuning, we will create a head with just 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.heads import FullyConnectedHead\n",
    "\n",
    "head = FullyConnectedHead(unique_id=\"default_head\", num_classes=2, in_plane=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us attach the head to the final block of the model, like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_heads({\"block3-2\": {head.unique_id: head}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the optimizer, we will be using RMSProp this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.optim import build_optimizer\n",
    "\n",
    "\n",
    "optimizer = build_optimizer({\n",
    "    \"name\": \"rmsprop\",\n",
    "    \"lr\": {\"name\": \"step\", \"values\": [0.1, 0.01]},\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"momentum\": 0.9,\n",
    "    \"alpha\": 0.9,\n",
    "    \"eps\": 1e-3,\n",
    "    \"num_epochs\": num_epochs\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to track the top-1 accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.meters import AccuracyMeter\n",
    "\n",
    "meters = [AccuracyMeter(topk=[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new directory to save the checkpoints for our fine tuning run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "fine_tuning_checkpoint_dir = f\"/tmp/checkpoint_{time.time()}\"\n",
    "os.mkdir(fine_tuning_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooks are also the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.hooks import CheckpointHook, LossLrMeterLoggingHook, ProgressBarHook\n",
    "\n",
    "hooks = [\n",
    "    ProgressBarHook(),\n",
    "    LossLrMeterLoggingHook(),\n",
    "    CheckpointHook(fine_tuning_checkpoint_dir, input_args={})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can setup our fine tuning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classy_vision.tasks import FineTuningTask\n",
    "\n",
    "fine_tuning_task = (\n",
    "    FineTuningTask()\n",
    "    .set_num_epochs(num_epochs)\n",
    "    .set_loss(loss)\n",
    "    .set_model(model)\n",
    "    .set_optimizer(optimizer)\n",
    "    .set_meters(meters)\n",
    "    .set_hooks(hooks)\n",
    "    .set_dataset(train_dataset, \"train\")\n",
    "    .set_dataset(test_dataset, \"test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a fine tuning task, there are some other configurations which need to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to re-train the trunk, so we will be freezing it. This is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<classy_vision.tasks.fine_tuning_task.FineTuningTask at 0x7f4df4feb850>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "bento_obj_id": "139972799543376"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_task.set_freeze_trunk(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to start training the heads from scratch, so we will be resetting them. This is required in this example since the pre-trained heads are not compatible with the heads in fine tuning (they have different number of classes). Otherwise, this is also optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<classy_vision.tasks.fine_tuning_task.FineTuningTask at 0x7f4df4feb850>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "bento_obj_id": "139972799543376"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_task.set_reset_heads(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to give our task the pre-trained checkpoint, which it'll need to start pre-training on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<classy_vision.tasks.fine_tuning_task.FineTuningTask at 0x7f4df4feb850>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "bento_obj_id": "139972799543376"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_task.set_pretrained_checkpoint(pretrained_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fine tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1031 124223.451 util.py:493] Model state load successful\n",
      "I1031 124223.453 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 124338.734 classy_trainer.py:53] Syncing meters on phase end...#########|\n",
      "I1031 124338.735 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 124338.736 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 124338.737 loss_lr_meter_logging_hook.py:88] Rank: 0, train phase: 0, processed batches: 63\n",
      "train loss: 0.008974908836304194, LR rate: 0.1\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0}}\n",
      "I1031 124338.738 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550943.3209333'...\n",
      "I1031 124339.084 classification_task.py:425] Recreating data loader for new phase\n",
      "I1031 124346.480 classy_trainer.py:53] Syncing meters on phase end...         |\n",
      "I1031 124346.481 classy_trainer.py:56] ...meters synced\n",
      "100% |########################################################################|\n",
      "I1031 124346.482 loss_lr_meter_logging_hook.py:60] End of phase metric values:\n",
      "I1031 124346.483 loss_lr_meter_logging_hook.py:88] Rank: 0, test phase: 0, processed batches: 7\n",
      "test loss: 0.0, LR rate: 0.1\n",
      "Meters:\n",
      "{'name': 'accuracy', 'value': {'top_1': 1.0}}\n",
      "I1031 124346.484 checkpoint_hook.py:69] Saving checkpoint to '/tmp/checkpoint_1572550943.3209333'...\n"
     ]
    }
   ],
   "source": [
    "trainer.train(fine_tuning_task)"
   ]
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "kernelspec": {
   "display_name": "Classy Vision (local)",
   "language": "python",
   "name": "classy_vision_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
