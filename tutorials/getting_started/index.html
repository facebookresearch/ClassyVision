<!DOCTYPE html><html lang=""><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Classy Vision · An end-to-end framework for image and video classification</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="An end-to-end framework for image and video classification"/><meta property="og:title" content="Classy Vision · An end-to-end framework for image and video classification"/><meta property="og:type" content="website"/><meta property="og:url" content="https://classyvision.ai/"/><meta property="og:description" content="An end-to-end framework for image and video classification"/><meta property="og:image" content="https://classyvision.ai/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://classyvision.ai/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/favicon.png" alt="Classy Vision"/><h2 class="headerTitleWithLogo">Classy Vision</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/facebookresearch/ClassyVision" target="_self">GitHub</a></li><li class=""><a target="_self"></a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span></span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Tutorials</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/">Overview</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Using Classy Vision</h3><ul class=""><li class="navListItem navListItemActive"><a class="navItem" href="/tutorials/getting_started">Getting started</a></li><li class="navListItem"><a class="navItem" href="/tutorials/ray_aws">Distributed training on AWS</a></li><li class="navListItem"><a class="navItem" href="/tutorials/classy_dataset">Creating a custom dataset</a></li><li class="navListItem"><a class="navItem" href="/tutorials/classy_model">Creating and using Classy Models</a></li><li class="navListItem"><a class="navItem" href="/tutorials/classy_loss">Creating a custom loss</a></li><li class="navListItem"><a class="navItem" href="/tutorials/video_classification">How to do video classification</a></li><li class="navListItem"><a class="navItem" href="/tutorials/fine_tuning">Fine Tuning a model</a></li><li class="navListItem"><a class="navItem" href="/tutorials/pet_aws">Elastic training</a></li><li class="navListItem"><a class="navItem" href="/tutorials/torchscript">Productionizing models</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="tutorialBody">
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js">
</script>
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js">
</script>
<body class="notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Getting-started-with-Classy-Vision">Getting started with Classy Vision<a class="anchor-link" href="#Getting-started-with-Classy-Vision">¶</a></h1>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Classy Vision is an end-to-end framework for image and video classification. Classy Vision makes it easy to write and launch distributed training jobs.</p>
<p>In this tutorial, we will cover:</p>
<ol>
<li>How to start a new project;</li>
<li>How to launch a single node training run; </li>
<li>How to launch a distributed training run; </li>
<li>How to visualize results with Tensorboard; </li>
<li>How to load checkpoints and interact with the trained model; </li>
<li>How to start training from a Jupyter notebook;</li>
<li>How to train a ResNet 50 model on ImageNet;</li>
</ol>
<h2 id="0.-Setup">0. Setup<a class="anchor-link" href="#0.-Setup">¶</a></h2><p>Make sure you have Classy Vision installed. To install it, run this in your terminal:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">classy_vision</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>If you would like to use GPUs for training, make sure your environment has a working version of PyTorch with CUDA:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The cell above should output <code>True</code>. Check out <a href="https://pytorch.org/get-started/locally/">this link</a> for more details on how to install PyTorch. For this tutorial, we will be using <a href="https://www.tensorflow.org/tensorboard">Tensorboard</a>. Install it with the following (on your terminal):</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">tensorboard</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="1.-Start-a-new-project">1. Start a new project<a class="anchor-link" href="#1.-Start-a-new-project">¶</a></h2><p>To start, let's create a new project. Run this in your terminal:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span> <span class="n">classy</span><span class="o">-</span><span class="n">project</span> <span class="n">my</span><span class="o">-</span><span class="n">project</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="n">cd</span> <span class="n">my</span><span class="o">-</span><span class="n">project</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>To launch a training run on the current machine, run the following:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span>  <span class="o">./</span><span class="n">classy_train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config</span> <span class="n">configs</span><span class="o">/</span><span class="n">template_config</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>That's it! You've launched your first training run. This trained a small MLP model on a dataset made of random noise, which is not that useful. The <code>classy-project</code> utility creates the scaffolding for you project, and you should modify it according to your needs. We'll learn how to customize your runs on the next few tutorials.</p>
<p>Let's take a look at what <code>classy-project</code> has created for us:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span> <span class="n">find</span> <span class="o">.</span> <span class="o">|</span> <span class="n">grep</span> <span class="o">-</span><span class="n">v</span> \<span class="o">.</span><span class="n">pyc</span> <span class="o">|</span> <span class="n">sort</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Here's what each folder means:</p>
<ul>
<li><code>configs</code>: stores your experiment configurations. Keeping all your experiments as separate configuration files helps making your research reproducible;</li>
<li><code>models</code>: code for your custom model architectures;</li>
<li><code>losses</code>: code for your custom loss functions;</li>
<li><code>datasets</code>: code for your custom datasets;</li>
<li><code>classy_train.py</code>: script to execute a training job; This uses the Classy Vision library to configure the job and execute it, and you might change it according to your needs;</li>
<li><code>template_config.json</code>: experiment configuration file. This file is read by <code>classy_train.py</code> to configure your training job and launch it.</li>
</ul>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Let's take a peek at the configuration file:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span> <span class="n">cat</span> <span class="n">configs</span><span class="o">/</span><span class="n">template_config</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>That file can be shared with other researchers whenever you want them to reproduce your experiments. We generate <code>json</code> files by default, but <code>YAML</code> will be officially supported soon.</p>
<h2 id="2.-Distributed-training">2. Distributed training<a class="anchor-link" href="#2.-Distributed-training">¶</a></h2><p><code>classy_train.py</code> can also be called from <code>torch.distributed.launch</code>, similar to regular PyTorch distributed scripts:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span> <span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">launch</span> <span class="o">--</span><span class="n">use_env</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">2</span> <span class="o">./</span><span class="n">classy_train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config</span> <span class="n">configs</span><span class="o">/</span><span class="n">template_config</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">distributed_backend</span> <span class="n">ddp</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>If you have two GPUs on your current machine, that command will launch one process per GPU and start a <a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">DistributedDataParallel</a> training run.</p>
<h2 id="3.-Tensorboard-integration">3. Tensorboard integration<a class="anchor-link" href="#3.-Tensorboard-integration">¶</a></h2><p><a href="https://www.tensorflow.org/tensorboard">Tensorboard</a> is a very useful tool for visualizing training progress. Classy Vision works with tensorboard out-of-the-box, just make sure you have it installed as described in the Setup section. By default <code>classy_train.py</code> will output tensorboard data in a subdirectory of your project directory (typically named <code>output_&lt;timestamp&gt;/tensorboard</code>), so in our case we can just launch tensorboard in the current working directory:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="n">load_ext</span> <span class="n">tensorboard</span>
<span class="o">%</span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span> <span class="o">.</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>You can also customize the tensorboard output directory by editing <code>classy_train.py</code>.</p>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4.-Loading-checkpoints">4. Loading checkpoints<a class="anchor-link" href="#4.-Loading-checkpoints">¶</a></h2><p>Now that we've run <code>classy_train.py</code>, let's see how to load the resulting model. At the end of execution, <code>classy_train.py</code> will print the checkpoint directory used for that run. Each run will output to a different directory, typically named <code>output_&lt;timestamp&gt;/checkpoints</code>. This can be configured by passing the <code>--checkpoint_folder</code> argument to <code>classy_train.py</code></p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">classy_vision.generic.util</span> <span class="kn">import</span> <span class="n">load_checkpoint</span>
<span class="kn">from</span> <span class="nn">classy_vision.models</span> <span class="kn">import</span> <span class="n">ClassyModel</span>

<span class="c1"># This is important: importing models here will register your custom models with Classy Vision</span>
<span class="c1"># so that it can instantiate them appropriately from the checkpoint file</span>
<span class="c1"># See more information at https://classyvision.ai/api/models.html#classy_vision.models.register_model</span>
<span class="kn">import</span> <span class="nn">models</span>

<span class="c1"># Update this with your actual directory:</span>
<span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="s1">'./output_&lt;timestamp&gt;/checkpoints'</span>
<span class="n">checkpoint_data</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ClassyModel</span><span class="o">.</span><span class="n">from_checkpoint</span><span class="p">(</span><span class="n">checkpoint_data</span><span class="p">)</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>That's it! You can now use that model for inference as usual.</p>
<h2 id="5.-Resuming-from-checkpoints">5. Resuming from checkpoints<a class="anchor-link" href="#5.-Resuming-from-checkpoints">¶</a></h2><p>Resuming from a checkpoint is as simple as training: <code>classy_train.py</code> takes a <code>--checkpoint_load_path</code> argument, which specifies the checkpoint path to resume from:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="err">!</span> <span class="o">./</span><span class="n">classy_train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">config</span> <span class="n">configs</span><span class="o">/</span><span class="n">template_config</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">checkpoint_load_path</span> <span class="o">./</span><span class="n">output_</span><span class="o">&lt;</span><span class="n">timestamp</span><span class="o">&gt;/</span><span class="n">checkpoints</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="6.-Interactive-development">6. Interactive development<a class="anchor-link" href="#6.-Interactive-development">¶</a></h2><p>Training scripts and configuration files are useful for running large training jobs on a GPU cluster (see our <a href="https://classyvision.ai/tutorials/ray_aws">AWS tutorial</a>), but a lot of day-to-day work happens interactively within Jupyter notebooks. Classy Vision is designed as a library that can be used without our built-in training scripts. Let's take a look at how to do the same training run as before, but within Jupyter instead of using <code>classy_train.py</code>:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">classy_vision</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">datasets.my_dataset</span> <span class="kn">import</span> <span class="n">MyDataset</span>
<span class="kn">from</span> <span class="nn">models.my_model</span> <span class="kn">import</span> <span class="n">MyModel</span>
<span class="kn">from</span> <span class="nn">losses.my_loss</span> <span class="kn">import</span> <span class="n">MyLoss</span>
<span class="kn">from</span> <span class="nn">classy_vision.dataset.transforms</span> <span class="kn">import</span> <span class="n">GenericImageTransform</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span>
    <span class="n">batchsize_per_replica</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">GenericImageTransform</span><span class="p">(</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
                    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                <span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>
    <span class="p">),</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">crop_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
    <span class="n">class_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span>
    <span class="n">batchsize_per_replica</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">GenericImageTransform</span><span class="p">(</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
                    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                <span class="p">),</span>
            <span class="p">]</span>
        <span class="p">)</span>
    <span class="p">),</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">crop_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
    <span class="n">class_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">classy_vision.tasks</span> <span class="kn">import</span> <span class="n">ClassificationTask</span>
<span class="kn">from</span> <span class="nn">classy_vision.optim</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">classy_vision.optim.param_scheduler</span> <span class="kn">import</span> <span class="n">LinearParamScheduler</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">MyLoss</span><span class="p">()</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">classy_vision.trainer</span> <span class="kn">import</span> <span class="n">LocalTrainer</span>

<span class="n">task</span> <span class="o">=</span> <span class="n">ClassificationTask</span><span class="p">()</span> \
        <span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">set_dataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="s2">"train"</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">set_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="s2">"test"</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">set_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">set_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">set_optimizer_schedulers</span><span class="p">({</span><span class="s2">"lr"</span><span class="p">:</span> <span class="n">LinearParamScheduler</span><span class="p">(</span><span class="n">start_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.009</span><span class="p">)})</span> \
        <span class="o">.</span><span class="n">set_num_epochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">LocalTrainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>That's it! Your model is trained now and ready for inference:</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">y_hat</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7.-Training-a-ResNet-50-on-ImageNet">7. Training a ResNet 50 on ImageNet<a class="anchor-link" href="#7.-Training-a-ResNet-50-on-ImageNet">¶</a></h2><p>We have looked at training models using synthetic data so far. A more typical workflow involves training a model on a real world dataset like <a href="http://image-net.org/">ImageNet</a>, which we will cover in this section.</p>
<p>To be able to train using ImageNet, first download the dataset archives from <a href="http://image-net.org/">http://image-net.org/</a>. Then, extract the data to a format expected by <a href="https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder"><code>torchvision.datasets.ImageFolder</code></a> inside subdirectories for the individual splits (<code>train</code> and <code>val</code>). We can then pass the root path containing these archives to the <a href="https://classyvision.ai/api/dataset.html#classy_vision.dataset.ImagePathDataset"><code>ImagePathDataset</code></a>.</p>
<p>The following configuration can be used to train a ResNet 50 on ImageNet to <code>76.4%</code> top-1 accuracy in 90 epochs. The optimizer configuration uses SGD with momentum, gradual learning rate warm up for the first 5 epochs and 1/10 learning rate drops at epochs 30, 60 and 80. The learning rate is calculated for a setup with 32 GPUs and can be scaled based on the overall batch size [1].</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"classification_task"</span><span class="p">,</span>
    <span class="s2">"num_epochs"</span><span class="p">:</span> <span class="mi">90</span><span class="p">,</span>
    <span class="s2">"loss"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"CrossEntropyLoss"</span>
    <span class="p">},</span>
    <span class="s2">"dataset"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"train"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"image_path"</span><span class="p">,</span>
            <span class="s2">"batchsize_per_replica"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s2">"num_samples"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">"use_shuffle"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">"transforms"</span><span class="p">:</span> <span class="p">[{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"apply_transform_to_key"</span><span class="p">,</span>
                <span class="s2">"transforms"</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"RandomResizedCrop"</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">:</span> <span class="mi">224</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"RandomHorizontalFlip"</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"ToTensor"</span><span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"Normalize"</span><span class="p">,</span>
                        <span class="s2">"mean"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                        <span class="s2">"std"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                    <span class="p">}</span>
                <span class="p">],</span>
                <span class="s2">"key"</span><span class="p">:</span> <span class="s2">"input"</span>
            <span class="p">}],</span>
            <span class="s2">"image_folder"</span><span class="p">:</span> <span class="s2">"/tmp/imagenet/train"</span>  <span class="c1"># replace with path to the extracted dataset</span>
        <span class="p">},</span>
        <span class="s2">"test"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"image_path"</span><span class="p">,</span>
            <span class="s2">"batchsize_per_replica"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s2">"num_samples"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">"use_shuffle"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">"transforms"</span><span class="p">:</span> <span class="p">[{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"apply_transform_to_key"</span><span class="p">,</span>
                <span class="s2">"transforms"</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"Resize"</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">:</span> <span class="mi">256</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"CenterCrop"</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">:</span> <span class="mi">224</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"ToTensor"</span><span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"Normalize"</span><span class="p">,</span>
                        <span class="s2">"mean"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                        <span class="s2">"std"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
                    <span class="p">}</span>
                <span class="p">],</span>
                <span class="s2">"key"</span><span class="p">:</span> <span class="s2">"input"</span>
            <span class="p">}],</span>
            <span class="s2">"image_folder"</span><span class="p">:</span> <span class="s2">"/tmp/imagenet/val"</span>  <span class="c1"># replace with path to the extracted dataset</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="s2">"meters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"accuracy"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"topk"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="s2">"model"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"resnet"</span><span class="p">,</span>
        <span class="s2">"num_blocks"</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s2">"small_input"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">"zero_init_bn_residuals"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">"heads"</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"fully_connected"</span><span class="p">,</span>
            <span class="s2">"unique_id"</span><span class="p">:</span> <span class="s2">"default_head"</span><span class="p">,</span>
            <span class="s2">"num_classes"</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
            <span class="s2">"fork_block"</span><span class="p">:</span> <span class="s2">"block3-2"</span><span class="p">,</span>
            <span class="s2">"in_plane"</span><span class="p">:</span> <span class="mi">2048</span>
          <span class="p">}</span>
        <span class="p">]</span>
    <span class="p">},</span>
    <span class="s2">"optimizer"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"sgd"</span><span class="p">,</span>
        <span class="s2">"param_schedulers"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"lr"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"composite"</span><span class="p">,</span>
                <span class="s2">"schedulers"</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"linear"</span><span class="p">,</span> <span class="s2">"start_lr"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s2">"end_lr"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">"name"</span><span class="p">:</span> <span class="s2">"multistep"</span><span class="p">,</span> <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.004</span><span class="p">,</span> <span class="mf">0.0004</span><span class="p">],</span> <span class="s2">"milestones"</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">]}</span>
                <span class="p">],</span>
                <span class="s2">"update_interval"</span><span class="p">:</span> <span class="s2">"epoch"</span><span class="p">,</span>
                <span class="s2">"interval_scaling"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"rescaled"</span><span class="p">,</span> <span class="s2">"fixed"</span><span class="p">],</span>
                <span class="s2">"lengths"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0555</span><span class="p">,</span> <span class="mf">0.9445</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="s2">"momentum"</span><span class="p">:</span> <span class="mf">0.9</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8.-Conclusion">8. Conclusion<a class="anchor-link" href="#8.-Conclusion">¶</a></h2><p>In this tutorial, we learned how to start a new project using Classy Vision, how to perform tranining locally and how to do multi-gpu training on a single machine. We also saw how to use Tensorboard to visualize training progress, how to load models from checkpoints and how resume training from a checkpoint file. We also went over how to use the ImageNet dataset to train a ResNet 50. In the next tutorials, we'll look into how to add custom datasets, models and loss functions to Classy Vision so you can adapt it to your needs, and how to launch distributed training on multiple nodes.</p>
</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="9.-References">9. References<a class="anchor-link" href="#9.-References">¶</a></h2><p>[1] Goyal, Priya, et al. "Accurate, large minibatch sgd: Training imagenet in 1 hour." arXiv preprint arXiv:1706.02677 (2017).</p>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</body></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/getting_started.ipynb" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Jupyter Notebook</a></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/getting_started.py" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Source Code</a></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Documentation</h5><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/facebookresearch/ClassyVision" data-count-href="https://github.com/facebookresearch/ClassyVision/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Classy Vision on GitHub">ClassyVision</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"><span>Copyright © 2023 Meta Platforms, Inc</span> <br/>Legal:  <a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a> <a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></section><script>
            (function() {
              var BAD_BASE = '/classyvision/';
              if (window.location.origin !== 'https://classyvision.ai') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://classyvision.ai/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div></body></html>