<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Classy Vision · An end-to-end framework for image and video classification</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="An end-to-end framework for image and video classification"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Classy Vision · An end-to-end framework for image and video classification"/><meta property="og:type" content="website"/><meta property="og:url" content="https://classyvision.ai/"/><meta property="og:description" content="An end-to-end framework for image and video classification"/><meta property="og:image" content="https://classyvision.ai/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://classyvision.ai/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/favicon.png" alt="Classy Vision"/><h2 class="headerTitleWithLogo">Classy Vision</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/facebookresearch/ClassyVision" target="_self">GitHub</a></li><li class=""><a target="_self"></a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="module-classy_vision.dataset">
<span id="dataset"></span><h1>Dataset<a class="headerlink" href="#module-classy_vision.dataset" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="classy_vision.dataset.CIFARDataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">CIFARDataset</code><span class="sig-paren">(</span><em class="sig-param">split: Optional[str], batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int], root: str, download: bool = None</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.CIFARDataset" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="classy_vision.dataset.CIFARDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">split: Optional[str], batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int], root: str, download: bool = None</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.CIFARDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for a ClassyDataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>split</strong> – When set, split of dataset to use (“train”, “test”)</p></li>
<li><p><strong>batchsize_per_replica</strong> – Positive integer indicating batch size for each
replica</p></li>
<li><p><strong>shuffle</strong> – Whether to shuffle between epochs</p></li>
<li><p><strong>transform</strong> – When set, transform to be applied to each sample</p></li>
<li><p><strong>num_samples</strong> – When set, this restricts the number of samples provided by
the dataset</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.CIFARDataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_cifar.CIFARDataset<a class="headerlink" href="#classy_vision.dataset.CIFARDataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a CIFARDataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for a CIFARDataset.
See <a class="reference internal" href="#classy_vision.dataset.CIFARDataset.__init__" title="classy_vision.dataset.CIFARDataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A CIFARDataset instance.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.ClassyDataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">ClassyDataset</code><span class="sig-paren">(</span><em class="sig-param">dataset: Sequence, split: Optional[str], batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int]</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Class representing a dataset abstraction.</p>
<p>This class wraps a <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="(in PyTorch vmaster (1.3.0a0+ee77ccb ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></a> via the <cite>dataset</cite> attribute
and configures the dataloaders needed to access the datasets.
Transforms which need to be applied to the data should be specified in this class.
ClassyDataset can be instantiated from a configuration file as well.</p>
<dl class="method">
<dt id="classy_vision.dataset.ClassyDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">dataset: Sequence, split: Optional[str], batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int]</em><span class="sig-paren">)</span> → None<a class="headerlink" href="#classy_vision.dataset.ClassyDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for a ClassyDataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>split</strong> – When set, split of dataset to use (“train”, “test”)</p></li>
<li><p><strong>batchsize_per_replica</strong> – Positive integer indicating batch size for each
replica</p></li>
<li><p><strong>shuffle</strong> – Whether to shuffle between epochs</p></li>
<li><p><strong>transform</strong> – When set, transform to be applied to each sample</p></li>
<li><p><strong>num_samples</strong> – When set, this restricts the number of samples provided by
the dataset</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyDataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_dataset.ClassyDataset<a class="headerlink" href="#classy_vision.dataset.ClassyDataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a ClassyDataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for the ClassyDataset.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A ClassyDataset instance.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyDataset.get_batchsize_per_replica">
<code class="sig-name descname">get_batchsize_per_replica</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyDataset.get_batchsize_per_replica" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the batch size per replica.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The batch size for each replica.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyDataset.get_global_batchsize">
<code class="sig-name descname">get_global_batchsize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyDataset.get_global_batchsize" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the global batch size, combined over all the replicas.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The overall batch size of the dataset.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyDataset.iterator">
<code class="sig-name descname">iterator</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyDataset.iterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterable which can be used to iterate over the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shuffle_seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Seed for the shuffle</p></li>
<li><p><strong>current_phase_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The epoch being fetched. Needed so that
each epoch has a different shuffle order</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An iterable over the data</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyDataset.parse_config">
<em class="property">classmethod </em><code class="sig-name descname">parse_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyDataset.parse_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function parses out common config options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – <p>A dict with the following string keys -</p>
<div class="line-block">
<div class="line"><em>batchsize_per_replica</em> (int): Must be a positive int, batch size</div>
<div class="line-block">
<div class="line">for each replica</div>
</div>
<div class="line"><em>use_shuffle</em> (bool): Whether to enable shuffling for the dataset</div>
<div class="line"><em>num_samples</em> (int, optional): When set, restricts the number of
samples in a dataset</div>
<div class="line"><em>transforms</em>: list of tranform configurations to be applied in order</div>
</div>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl>
<dt>A tuple containing the following variables -</dt><dd><div class="line-block">
<div class="line"><em>transform_config</em>: Config for the dataset transform. Can be passed to</div>
<div class="line-block">
<div class="line"><a class="reference internal" href="transforms.html#classy_vision.dataset.transforms.build_transform" title="classy_vision.dataset.transforms.build_transform"><code class="xref py py-func docutils literal notranslate"><span class="pre">transforms.build_transform()</span></code></a></div>
</div>
<div class="line"><em>batchsize_per_replica</em>: Batch size per replica</div>
<div class="line"><em>shuffle</em>: Whether we should shuffle between epochs</div>
<div class="line"><em>num_samples</em>: When set, restricts the number of samples in a dataset</div>
</div>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.ClassyVideoDataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">ClassyVideoDataset</code><span class="sig-paren">(</span><em class="sig-param">dataset: Any, split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], clips_per_video: int</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyVideoDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Interface specifying what a ClassyVision video dataset is expected to provide.</p>
<p>This dataset considers every video as a collection of video clips of fixed size,
specified by <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code>, where the step in frames between each clip
is given by <code class="docutils literal notranslate"><span class="pre">step_between_clips</span></code>. It uses a clip sampler to sample
a specified number of clips (<code class="docutils literal notranslate"><span class="pre">clips_per_video</span></code>) from each video.
For training set, a random clip sampler is used to
sample a small number of clips (e.g. 1) from each video
For testing set, a uniform clip sampler is used to evenly sample a large
number of clips (e.g. 10) from the video.</p>
<p>To give an example, for 2 videos with 10 and 15 frames respectively,
if <code class="docutils literal notranslate"><span class="pre">frames_per_clip=5</span></code> and <code class="docutils literal notranslate"><span class="pre">step_between_clips=5</span></code>, the dataset size
will be (2 + 3) = 5, where the first two elements will come from video 1,
and the next three elements from video 2. Note that we drop clips which do
not have exactly <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code> elements, so not all frames in a video
may be present.</p>
<dl class="method">
<dt id="classy_vision.dataset.ClassyVideoDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">dataset: Any, split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], clips_per_video: int</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyVideoDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The constructor method of ClassyVideoDataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> – the underlying video dataset from either TorchVision or other
source. It should have an attribute <em>video_clips</em> of type
<a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/video_utils.py#L46/">torchvision.datasets.video_utils.VideoClips</a></p></li>
<li><p><strong>split</strong> – dataset split. Must be either “train” or “test”</p></li>
<li><p><strong>batchsize_per_replica</strong> – batch size per model replica</p></li>
<li><p><strong>shuffle</strong> – If true, shuffle video clips.</p></li>
<li><p><strong>transform</strong> – callable function to transform video clip sample from
ClassyVideoDataset</p></li>
<li><p><strong>num_samples</strong> – If provided, return at most <cite>num_samples</cite> video clips</p></li>
<li><p><strong>clips_per_video</strong> – The number of clips sampled from each video</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyVideoDataset.iterator">
<code class="sig-name descname">iterator</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyVideoDataset.iterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides the implementation in parent class <cite>ClassyDataset</cite>.
See parent class method <a class="reference internal" href="#classy_vision.dataset.ClassyDataset.iterator" title="classy_vision.dataset.ClassyDataset.iterator"><code class="xref py py-func docutils literal notranslate"><span class="pre">ClassyDataset.iterator()</span></code></a> for all the
usable positional and keyword arguments.</p>
<p>Sets “fork” as start method for python multiprocessing module for
comaptibility with video decoding using cpp python extensions.</p>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyVideoDataset.load_metadata">
<em class="property">classmethod </em><code class="sig-name descname">load_metadata</code><span class="sig-paren">(</span><em class="sig-param">filepath: str</em>, <em class="sig-param">video_dir: Optional[str] = None</em>, <em class="sig-param">update_file_path: bool = False</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="headerlink" href="#classy_vision.dataset.ClassyVideoDataset.load_metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Load pre-computed video dataset meta data.</p>
<p>Video dataset meta data computation takes minutes on small dataset and hours
on large dataset, and thus is time-consuming. However, it only needs to be
computed once, and can be saved into a file via <a class="reference internal" href="#classy_vision.dataset.ClassyVideoDataset.save_metadata" title="classy_vision.dataset.ClassyVideoDataset.save_metadata"><code class="xref py py-func docutils literal notranslate"><span class="pre">save_metadata()</span></code></a>.</p>
<p>The format of meta data is defined in <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/video_utils.py#L131/">TorchVision</a>.</p>
<p>For each video, meta data contains the video file path, presentation
timestamps of all video frames, and video fps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filepath</strong> – file path of pre-computed meta data</p></li>
<li><p><strong>video_dir</strong> – If provided, the folder where video files are stored.</p></li>
<li><p><strong>update_file_path</strong> – If true, replace the directory part of video file path
in meta data with the actual video directory provided in <cite>video_dir</cite>.
This is necessary for successsfully reusing pre-computed meta data
when video directory has been moved and is no longer consitent
with the full video file path saved in the meta data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyVideoDataset.parse_config">
<em class="property">classmethod </em><code class="sig-name descname">parse_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyVideoDataset.parse_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Parse config to prepare arguments needed by the class constructor.</p>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyVideoDataset.save_metadata">
<em class="property">classmethod </em><code class="sig-name descname">save_metadata</code><span class="sig-paren">(</span><em class="sig-param">metadata: Dict[str, Any], filepath: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ClassyVideoDataset.save_metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Save dataset meta data into a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metadata</strong> – dataset meta data, which contains video meta infomration, such
as video file path, video fps, video frame timestamp in each video.
For the format of dataset meta data, check the <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/video_utils.py#L132-L137/">TorchVision
documentation</a>.</p></li>
<li><p><strong>filepath</strong> – file path where the meta data will be saved</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ClassyVideoDataset.video_clips">
<em class="property">property </em><code class="sig-name descname">video_clips</code><a class="headerlink" href="#classy_vision.dataset.ClassyVideoDataset.video_clips" title="Permalink to this definition">¶</a></dt>
<dd><p>Attribute video_clips.</p>
<dl class="simple">
<dt>It is used in <code class="docutils literal notranslate"><span class="pre">_get_sampler</span></code> method. Its data type should be</dt><dd><p><a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/video_utils.py#L46/">torchvision.datasets.video_utils.VideoClips</a>.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.HMDB51Dataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">HMDB51Dataset</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], frames_per_clip: int, video_width: int, video_height: int, video_min_dimension: int, audio_samples: int, step_between_clips: int, frame_rate: Optional[int], clips_per_video: int, video_dir: str, splits_dir: str, fold: int, metadata_filepath: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.HMDB51Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/">HMDB51</a> is an action recognition video dataset,
and it has 51 classes.</p>
<p>It is built on top of <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/hmdb51.py#L10/">HMDB51</a> dataset class in TorchVision.</p>
<dl class="method">
<dt id="classy_vision.dataset.HMDB51Dataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], frames_per_clip: int, video_width: int, video_height: int, video_min_dimension: int, audio_samples: int, step_between_clips: int, frame_rate: Optional[int], clips_per_video: int, video_dir: str, splits_dir: str, fold: int, metadata_filepath: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.HMDB51Dataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The constructor of HMDB51Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>split</strong> – dataset split which can be either “train” or “test”</p></li>
<li><p><strong>batchsize_per_replica</strong> – batch size per model replica</p></li>
<li><p><strong>shuffle</strong> – If true, shuffle the dataset</p></li>
<li><p><strong>transform</strong> – a dict where transforms video and audio data</p></li>
<li><p><strong>num_samples</strong> – if not None, it will subsample dataset</p></li>
<li><p><strong>frames_per_clip</strong> – the number of frames in a video clip</p></li>
<li><p><strong>video_width</strong> – rescaled video width. If 0, keep original width</p></li>
<li><p><strong>video_height</strong> – rescaled video height. If 0, keep original height</p></li>
<li><p><strong>video_min_dimension</strong> – rescale video so that min(height, width) =
<code class="docutils literal notranslate"><span class="pre">video_min_dimension</span></code>. If 0, keep original video resolution.
Note only one of (<code class="docutils literal notranslate"><span class="pre">video_width</span></code>, <code class="docutils literal notranslate"><span class="pre">video_height</span></code>) and
(<code class="docutils literal notranslate"><span class="pre">video_min_dimension</span></code>) can be set</p></li>
<li><p><strong>audio_samples</strong> – desired audio sample rate. If 0, keep original
audio sample rate.</p></li>
<li><p><strong>step_between_clips</strong> – Number of frames between each clip.</p></li>
<li><p><strong>frame_rate</strong> – desired video frame rate. If None, keep
orignal video frame rate.</p></li>
<li><p><strong>clips_per_video</strong> – Number of clips to sample from each video</p></li>
<li><p><strong>video_dir</strong> – path to video folder</p></li>
<li><p><strong>splits_dir</strong> – path to dataset splitting file folder</p></li>
<li><p><strong>fold</strong> – HMDB51 dataset has 3 folds. Valid values are 1, 2 and 3.</p></li>
<li><p><strong>metadata_filepath</strong> – path to the dataset meta data</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.HMDB51Dataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_hmdb51.HMDB51Dataset<a class="headerlink" href="#classy_vision.dataset.HMDB51Dataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a HMDB51Dataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for a HMDB51Dataset.
See <a class="reference internal" href="#classy_vision.dataset.HMDB51Dataset.__init__" title="classy_vision.dataset.HMDB51Dataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A HMDB51Dataset instance.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.ImageNetDataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">ImageNetDataset</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int], root: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ImageNetDataset" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="classy_vision.dataset.ImageNetDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int], root: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ImageNetDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for a ClassyDataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>split</strong> – When set, split of dataset to use (“train”, “test”)</p></li>
<li><p><strong>batchsize_per_replica</strong> – Positive integer indicating batch size for each
replica</p></li>
<li><p><strong>shuffle</strong> – Whether to shuffle between epochs</p></li>
<li><p><strong>transform</strong> – When set, transform to be applied to each sample</p></li>
<li><p><strong>num_samples</strong> – When set, this restricts the number of samples provided by
the dataset</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ImageNetDataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_imagenet.ImageNetDataset<a class="headerlink" href="#classy_vision.dataset.ImageNetDataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a ImageNetDataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for a ImageNetDataset.
See <a class="reference internal" href="#classy_vision.dataset.ImageNetDataset.__init__" title="classy_vision.dataset.ImageNetDataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A ImageNetDataset instance.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.ImagePathDataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">ImagePathDataset</code><span class="sig-paren">(</span><em class="sig-param">batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int], image_paths: Union[str, List[str]], targets: Optional[List[Any]] = None, split: Optional[str] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ImagePathDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset which reads images from a local filesystem. Implements ClassyDataset.</p>
<dl class="simple">
<dt>The image paths provided can be:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>A single directory location, in which case the data is expected to be</dt><dd><p>arranged in a format similar to <a class="reference external" href="https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder" title="(in PyTorch vmaster (1.3.0a0+ee77ccb ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchvision.datasets.ImageFolder</span></code></a>.
The targets will be inferred from the directory structure.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A list of paths, in which case the list will contain the paths to all the</dt><dd><p>images. In this situation, the targets can be specified by the targets
argument.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="classy_vision.dataset.ImagePathDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: Optional[int], image_paths: Union[str, List[str]], targets: Optional[List[Any]] = None, split: Optional[str] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ImagePathDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor for ImagePathDataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batchsize_per_replica</strong> – Positive integer indicating batch size for each
replica</p></li>
<li><p><strong>shuffle</strong> – Whether we should shuffle between epochs</p></li>
<li><p><strong>transform</strong> – Transform to be applied to each sample</p></li>
<li><p><strong>num_samples</strong> – When set, this restricts the number of samples provided by
the dataset</p></li>
<li><p><strong>image_paths</strong> – A directory or a list of file paths where images can be found.</p></li>
<li><p><strong>targets</strong> – If a list of file paths is specified, this argument can
be used to specify a target for each path (must be same length
as list of file paths). If no targets are needed or image_paths is
a directory, then targets should be None.</p></li>
<li><p><strong>split</strong> – Split of dataset (“train”, “test”)</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.ImagePathDataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any], image_paths: Union[str, List[str]], targets: Optional[List[Any]] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.ImagePathDataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates ImagePathDataset from a config.</p>
<p>Because image_paths / targets can be arbitrarily long, we
allow passing in the image paths and targets from python in
addition to the configuration parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> – A configuration for ImagePathDataset.
See <a class="reference internal" href="#classy_vision.dataset.ImagePathDataset.__init__" title="classy_vision.dataset.ImagePathDataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p></li>
<li><p><strong>image_paths</strong> – Directory or list of image paths.
See <a class="reference internal" href="#classy_vision.dataset.ImagePathDataset.__init__" title="classy_vision.dataset.ImagePathDataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for more details</p></li>
<li><p><strong>targets</strong> – Optional list of targets for dataset.
See <a class="reference internal" href="#classy_vision.dataset.ImagePathDataset.__init__" title="classy_vision.dataset.ImagePathDataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for more details</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.Kinetics400Dataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">Kinetics400Dataset</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], frames_per_clip: int, video_width: int, video_height: int, video_min_dimension: int, audio_samples: int, audio_channels: int, step_between_clips: int, frame_rate: Optional[int], clips_per_video: int, video_dir: str, extensions: List[str], metadata_filepath: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.Kinetics400Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/">Kinetics-400</a> is an action recognition video dataset,
and it has 400 classes.
<a class="reference external" href="https://arxiv.org/pdf/1705.06950.pdf">Original publication</a></p>
<p>We assume videos are already trimmed to 10-second clip, and are stored in a
folder.</p>
<p>It is built on top of <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/kinetics.py#L7/">Kinetics400</a> dataset class in TorchVision.</p>
<dl class="method">
<dt id="classy_vision.dataset.Kinetics400Dataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], frames_per_clip: int, video_width: int, video_height: int, video_min_dimension: int, audio_samples: int, audio_channels: int, step_between_clips: int, frame_rate: Optional[int], clips_per_video: int, video_dir: str, extensions: List[str], metadata_filepath: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.Kinetics400Dataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The constructor of Kinetics400Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>split</strong> – dataset split which can be either “train” or “test”</p></li>
<li><p><strong>batchsize_per_replica</strong> – batch size per model replica</p></li>
<li><p><strong>shuffle</strong> – If true, shuffle the dataset</p></li>
<li><p><strong>transform</strong> – a dict where transforms video and audio data</p></li>
<li><p><strong>num_samples</strong> – if provided, it will subsample dataset</p></li>
<li><p><strong>frames_per_clip</strong> – the No. of frames in a video clip</p></li>
<li><p><strong>video_width</strong> – rescaled video width. If 0, keep original width</p></li>
<li><p><strong>video_height</strong> – rescaled video height. If 0, keep original height</p></li>
<li><p><strong>video_min_dimension</strong> – rescale video so that min(height, width) =
video_min_dimension. If 0, keep original video resolution. Note
only one of (video_width, video_height) and (video_min_dimension)
can be set</p></li>
<li><p><strong>audio_samples</strong> – desired audio sample rate. If 0, keep original
audio sample rate</p></li>
<li><p><strong>audio_channels</strong> – desire No. of audio channel. If 0, keep original audio
channels</p></li>
<li><p><strong>step_between_clips</strong> – Number of frames between each clip.</p></li>
<li><p><strong>frame_rate</strong> – desired video frame rate. If None, keep
orignal video frame rate.</p></li>
<li><p><strong>clips_per_video</strong> – Number of clips to sample from each video</p></li>
<li><p><strong>video_dir</strong> – path to video folder</p></li>
<li><p><strong>extensions</strong> – A list of file extensions, such as “avi” and “mp4”. Only
video matching those file extensions are added to the dataset</p></li>
<li><p><strong>metadata_filepath</strong> – path to the dataset meta data</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.Kinetics400Dataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_kinetics400.Kinetics400Dataset<a class="headerlink" href="#classy_vision.dataset.Kinetics400Dataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a Kinetics400Dataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for a Kinetics400Dataset.
See <a class="reference internal" href="#classy_vision.dataset.Kinetics400Dataset.__init__" title="classy_vision.dataset.Kinetics400Dataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A Kinetics400Dataset instance.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.SyntheticImageDataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">SyntheticImageDataset</code><span class="sig-paren">(</span><em class="sig-param">batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: int, crop_size: int, class_ratio: float, seed: int, split: Optional[str] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.SyntheticImageDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Classy Dataset which produces random synthetic images with binary targets.</p>
<p>The underlying dataset sets targets based on the channels in the image, so users can
validate their setup by checking if they can get 100% accuracy on this dataset.
Useful for testing since the dataset is much faster to initialize and fetch samples
from, compared to real world datasets.</p>
<dl class="method">
<dt id="classy_vision.dataset.SyntheticImageDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">batchsize_per_replica: int, shuffle: bool, transform: Optional[Callable], num_samples: int, crop_size: int, class_ratio: float, seed: int, split: Optional[str] = None</em><span class="sig-paren">)</span> → None<a class="headerlink" href="#classy_vision.dataset.SyntheticImageDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batchsize_per_replica</strong> – Positive integer indicating batch size for each
replica</p></li>
<li><p><strong>shuffle</strong> – Whether we should shuffle between epochs</p></li>
<li><p><strong>transform</strong> – When specified, transform to be applied to each sample</p></li>
<li><p><strong>num_samples</strong> – Number of samples to return</p></li>
<li><p><strong>crop_size</strong> – Image size, used for both height and width</p></li>
<li><p><strong>class_ratio</strong> – Ratio of the distribution of target classes</p></li>
<li><p><strong>seed</strong> – Seed used for image generation. Use the same seed to generate the same
set of samples.</p></li>
<li><p><strong>split</strong> – When specified, split of dataset to use</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.SyntheticImageDataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_synthetic_image.SyntheticImageDataset<a class="headerlink" href="#classy_vision.dataset.SyntheticImageDataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a SyntheticImageDataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for a SyntheticImageDataset.
See <a class="reference internal" href="#classy_vision.dataset.SyntheticImageDataset.__init__" title="classy_vision.dataset.SyntheticImageDataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A SyntheticImageDataset instance.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.SyntheticVideoDataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">SyntheticVideoDataset</code><span class="sig-paren">(</span><em class="sig-param">num_classes: int</em>, <em class="sig-param">split: str</em>, <em class="sig-param">batchsize_per_replica: int</em>, <em class="sig-param">shuffle: bool</em>, <em class="sig-param">transform: Callable</em>, <em class="sig-param">num_samples: int</em>, <em class="sig-param">frames_per_clip: int</em>, <em class="sig-param">video_width: int</em>, <em class="sig-param">video_height: int</em>, <em class="sig-param">audio_samples: int</em>, <em class="sig-param">clips_per_video: int</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.SyntheticVideoDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Classy Dataset which produces random synthetic video clips.</p>
<p>Useful for testing since the dataset is much faster to initialize and fetch samples
from, compared to real world datasets.</p>
<dl class="simple">
<dt>Note: Unlike <a class="reference internal" href="#classy_vision.dataset.SyntheticImageDataset" title="classy_vision.dataset.SyntheticImageDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">SyntheticImageDataset</span></code></a>, this dataset generates targets</dt><dd><p>randomly, independent of the video clips.</p>
</dd>
</dl>
<dl class="method">
<dt id="classy_vision.dataset.SyntheticVideoDataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">num_classes: int</em>, <em class="sig-param">split: str</em>, <em class="sig-param">batchsize_per_replica: int</em>, <em class="sig-param">shuffle: bool</em>, <em class="sig-param">transform: Callable</em>, <em class="sig-param">num_samples: int</em>, <em class="sig-param">frames_per_clip: int</em>, <em class="sig-param">video_width: int</em>, <em class="sig-param">video_height: int</em>, <em class="sig-param">audio_samples: int</em>, <em class="sig-param">clips_per_video: int</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.SyntheticVideoDataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The constructor of SyntheticVideoDataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> – Number of classes in the generated targets.</p></li>
<li><p><strong>split</strong> – Split of dataset to use</p></li>
<li><p><strong>batchsize_per_replica</strong> – batch size per model replica</p></li>
<li><p><strong>shuffle</strong> – Whether we should shuffle between epochs</p></li>
<li><p><strong>transform</strong> – Transform to be applied to each sample</p></li>
<li><p><strong>num_samples</strong> – Number of samples to return</p></li>
<li><p><strong>frames_per_clip</strong> – Number of frames in a video clip</p></li>
<li><p><strong>video_width</strong> – Width of the video clip</p></li>
<li><p><strong>video_height</strong> – Height of the video clip</p></li>
<li><p><strong>audio_samples</strong> – Audio sample rate</p></li>
<li><p><strong>clips_per_video</strong> – Number of clips per video</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.SyntheticVideoDataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_synthetic_video.SyntheticVideoDataset<a class="headerlink" href="#classy_vision.dataset.SyntheticVideoDataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a SyntheticVideoDataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for a SyntheticVideoDataset.
See <a class="reference internal" href="#classy_vision.dataset.SyntheticVideoDataset.__init__" title="classy_vision.dataset.SyntheticVideoDataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A SyntheticVideoDataset instance.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.SyntheticVideoDataset.video_clips">
<em class="property">property </em><code class="sig-name descname">video_clips</code><a class="headerlink" href="#classy_vision.dataset.SyntheticVideoDataset.video_clips" title="Permalink to this definition">¶</a></dt>
<dd><p>Attribute video_clips.</p>
<dl class="simple">
<dt>It is used in <code class="docutils literal notranslate"><span class="pre">_get_sampler</span></code> method. Its data type should be</dt><dd><p><a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/video_utils.py#L46/">torchvision.datasets.video_utils.VideoClips</a>.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="classy_vision.dataset.UCF101Dataset">
<em class="property">class </em><code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">UCF101Dataset</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], frames_per_clip: int, video_width: int, video_height: int, video_min_dimension: int, audio_samples: int, step_between_clips: int, frame_rate: Optional[int], clips_per_video: int, video_dir: str, splits_dir: str, fold: int, metadata_filepath: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.UCF101Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.crcv.ucf.edu/data/UCF101.php/">UCF101</a> is an action
recognition video dataset, and it has 101 classes.</p>
<p>It is built on top of <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/ucf101.py#L10">UCF101</a> dataset class in TorchVision.</p>
<dl class="method">
<dt id="classy_vision.dataset.UCF101Dataset.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">split: str, batchsize_per_replica: int, shuffle: bool, transform: Callable, num_samples: Optional[int], frames_per_clip: int, video_width: int, video_height: int, video_min_dimension: int, audio_samples: int, step_between_clips: int, frame_rate: Optional[int], clips_per_video: int, video_dir: str, splits_dir: str, fold: int, metadata_filepath: str</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.UCF101Dataset.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The constructor of UCF101Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>split</strong> – dataset split which can be either “train” or “test”</p></li>
<li><p><strong>batchsize_per_replica</strong> – batch size per model replica</p></li>
<li><p><strong>shuffle</strong> – If true, shuffle the dataset</p></li>
<li><p><strong>transform</strong> – a dict where transforms video and audio data</p></li>
<li><p><strong>num_samples</strong> – if not None, it will subsample dataset</p></li>
<li><p><strong>frames_per_clip</strong> – the No. of frames in a video clip</p></li>
<li><p><strong>video_width</strong> – rescaled video width. If 0, keep original width</p></li>
<li><p><strong>video_height</strong> – rescaled video height. If 0, keep original height</p></li>
<li><p><strong>video_min_dimension</strong> – rescale video so that min(height, width) =
<code class="docutils literal notranslate"><span class="pre">video_min_dimension</span></code>. If 0, keep original video resolution.
Note only one of (<code class="docutils literal notranslate"><span class="pre">video_width</span></code>, <code class="docutils literal notranslate"><span class="pre">video_height</span></code>)
and (<code class="docutils literal notranslate"><span class="pre">video_min_dimension</span></code>) can be set</p></li>
<li><p><strong>audio_samples</strong> – desired audio sample rate. If 0, keep original
audio sample rate.</p></li>
<li><p><strong>step_between_clips</strong> – Number of frames between each clip.</p></li>
<li><p><strong>frame_rate</strong> – desired video frame rate. If None, keep original video
frame rate.</p></li>
<li><p><strong>clips_per_video</strong> – Number of clips to sample from each video</p></li>
<li><p><strong>video_dir</strong> – path to video folder</p></li>
<li><p><strong>splits_dir</strong> – path to dataset splitting file folder</p></li>
<li><p><strong>fold</strong> – UCF101 dataset has 3 folds. Valid values are 1, 2 and 3.</p></li>
<li><p><strong>metadata_filepath</strong> – path to the dataset meta data</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="classy_vision.dataset.UCF101Dataset.from_config">
<em class="property">classmethod </em><code class="sig-name descname">from_config</code><span class="sig-paren">(</span><em class="sig-param">config: Dict[str, Any]</em><span class="sig-paren">)</span> → classy_vision.dataset.classy_ucf101.UCF101Dataset<a class="headerlink" href="#classy_vision.dataset.UCF101Dataset.from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a UCF101Dataset from a configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config</strong> – A configuration for a UCF101Dataset.
See <a class="reference internal" href="#classy_vision.dataset.UCF101Dataset.__init__" title="classy_vision.dataset.UCF101Dataset.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> for parameters expected in the config.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A UCF101Dataset instance.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="function">
<dt id="classy_vision.dataset.build_dataset">
<code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">build_dataset</code><span class="sig-paren">(</span><em class="sig-param">config</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.build_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds a <a class="reference internal" href="#classy_vision.dataset.ClassyDataset" title="classy_vision.dataset.ClassyDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClassyDataset</span></code></a> from a config.</p>
<p>This assumes a ‘name’ key in the config which is used to determine what
dataset class to instantiate. For instance, a config <cite>{“name”: “my_dataset”,
“folder”: “/data”}</cite> will find a class that was registered as “my_dataset”
(see <a class="reference internal" href="#classy_vision.dataset.register_dataset" title="classy_vision.dataset.register_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">register_dataset()</span></code></a>) and call .from_config on it.</p>
</dd></dl>
<dl class="function">
<dt id="classy_vision.dataset.register_dataset">
<code class="sig-prename descclassname">classy_vision.dataset.</code><code class="sig-name descname">register_dataset</code><span class="sig-paren">(</span><em class="sig-param">name</em><span class="sig-paren">)</span><a class="headerlink" href="#classy_vision.dataset.register_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a <a class="reference internal" href="#classy_vision.dataset.ClassyDataset" title="classy_vision.dataset.ClassyDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClassyDataset</span></code></a> subclass.</p>
<p>This decorator allows Classy Vision to instantiate a subclass of
ClassyDataset from a configuration file, even if the class itself is not
part of the Classy Vision framework. To use it, apply this decorator to a
ClassyDataset subclass like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@register_dataset</span><span class="p">(</span><span class="s2">"my_dataset"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">ClassyDataset</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>To instantiate a dataset from a configuration file, see
<a class="reference internal" href="#classy_vision.dataset.build_dataset" title="classy_vision.dataset.build_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">build_dataset()</span></code></a>.</p>
</dd></dl>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Classy Vision</a></h1>
<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="heads.html">Heads</a></li>
<li class="toctree-l1"><a class="reference internal" href="hooks.html">Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="losses.html">Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="meters.html">Meters</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="param_scheduler.html">Param Schedulers</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="trainer.html">Trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="transforms.html">Transforms</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="index.html" title="previous chapter">Classy Vision’s API Reference</a></li>
<li>Next: <a href="heads.html" title="next chapter">Heads</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Documentation</h5><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/facebookresearch/ClassyVision" data-count-href="https://github.com/facebookresearch/ClassyVision/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Classy Vision on GitHub">ClassyVision</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"><span>Copyright © 2019 Facebook Inc.</span> </section><script>
            (function() {
              var BAD_BASE = '/classyvision/';
              if (window.location.origin !== 'https://classyvision.ai') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://classyvision.ai/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div></body></html>